{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM3MmcuVCrmqMdeLqffnntf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfadaei116/Deep-Learning-Course/blob/master/CA1/Q8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00v0DfThotAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "095ef159-f998-4aa1-9ab9-129b561fdf57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzWlDQhUroVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "from sklearn.utils import shuffle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLI63oE_ruO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/Reduced_Test_Data.csv', header = None)\n",
        "Test_label = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/testLabels.csv', header = None)\n",
        "Train_data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/Reduced_Train_Data.csv', header = None)\n",
        "Train_label = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/trainLabels.csv', header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lguls3tmwJmw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data = Test_data.to_numpy()\n",
        "Test_label = Test_label.to_numpy()\n",
        "Train_data = Train_data.to_numpy()\n",
        "Train_label = Train_label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1AtEEikwNIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxD = np.max(Train_data, axis=0)\n",
        "minD = np.min(Train_data, axis=0)\n",
        "delta = maxD - minD\n",
        "Train_data = Train_data - minD\n",
        "Test_data = Test_data - minD\n",
        "Train_data = 2 * (Train_data/delta) - 1\n",
        "Test_data = 2 * (Test_data/delta) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_C-SErWwPUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 200\n",
        "noise_data = np.random.normal(loc=0, scale=0.2, size=(num, len(Train_data[0])))\n",
        "noise_label = 10 * np.ones(shape=(num,1))\n",
        "Train_data = np.concatenate((Train_data, noise_data))\n",
        "Train_label = np.concatenate((Train_label, noise_label))\n",
        "Train_data, Train_label =shuffle(Train_data, Train_label, random_state=0)\n",
        "Train_label = (Train_label).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQaYSgrKwTdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(x, np.zeros_like(x))\n",
        "\n",
        "def Cal_accuracy(True_label, Estimated_label):\n",
        "  return np.count_nonzero(np.transpose(True_label)==np.array(Estimated_label))/True_label.size\n",
        "\n",
        "def step(x):\n",
        "  return 1*(x > np.zeros_like(x))\n",
        "\n",
        "def encode(vect, idx, landa):\n",
        "  temp = np.multiply(step(landa - vect),-1)\n",
        "  if idx != 10:\n",
        "    temp[idx] = 1\n",
        "  return temp\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * np.multiply(x, 1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "def Dgelu(x):\n",
        "  return np.divide(0.053516 * np.power(x, 3) + np.multiply(0.398942, x) , np.power(np.cosh(0.0356774 * np.power(x, 3) +np.multiply(0.79788, x)),2)) + 0.5 * ( 1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "def RBF_encode(data, number_class, dim):\n",
        "  data = np.reshape(data, (dim,int(data.size/dim)), order='F')\n",
        "  data = LA.norm(data,1, axis = 0)\n",
        "  data = np.reshape(data, (number_class, int(data.size/number_class)), order='F')\n",
        "  return data\n",
        "\n",
        "def expand(x):\n",
        "  temp = []\n",
        "  for i in range(len(x)):\n",
        "    temp.append(x[i])\n",
        "    temp.append(x[i])\n",
        "  return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1WIbC-Rw0GV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network:\n",
        "  def __init__(self, input_node, hidden_layer, hidden_node, output_node):\n",
        "    self.number_input_node = input_node\n",
        "    self.number_hidden_layer = hidden_layer\n",
        "    self.number_hidden_node = hidden_node\n",
        "    self.number_class_output = output_node\n",
        "    self.distance_dim = 2\n",
        "    self.weight = {}\n",
        "    self.layer = {}\n",
        "    self.batch_data = {}\n",
        "    self.batch_label = {}\n",
        "    self.diff_weight = {}\n",
        "    self.score = []\n",
        "    self.result = []\n",
        "    self.init_weight()\n",
        "    self.loss = []\n",
        "    self.back_prob_output = []\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.diff_weight[\"w\" + str(i) + \"_prev\"] = 0\n",
        "      self.diff_weight[\"b\" + str(i) + \"_prev\"] = 0\n",
        "    self.momentum = 0.9\n",
        "    self.learning_rate = 0.001\n",
        "    self.number_turn = 100\n",
        "    self.batchS = 128\n",
        "    self.accuracy_graph = []\n",
        "    self.loss_graph = []\n",
        "    self.landa = 50\n",
        "    self.attack_rate = 0.5\n",
        "\n",
        "  def set_turn(self, x):\n",
        "    self.number_turn = x\n",
        "\n",
        "  def set_learning_rate(self, x):\n",
        "    self.learning_rate = x\n",
        "\n",
        "  def set_batch_size(self, x):\n",
        "    self.batchS = x\n",
        "  \n",
        "  def load_weights(self):\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.weight[\"w\" + str(i)] = (pd.read_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/w\" + str(i) + \".csv\", header=None)).to_numpy()\n",
        "      self.weight[\"b\" + str(i)] = (pd.read_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/b\" + str(i) + \".csv\", header=None)).to_numpy()\n",
        "\n",
        "  def init_weight(self):\n",
        "    self.weight[\"w0\"] = np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[0], self.number_input_node))\n",
        "    self.weight[\"b0\"] = np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[0], 1))\n",
        "    for i in range(self.number_hidden_layer - 1):\n",
        "      self.weight[\"w\" + str(i+1)] = (np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[i+1], self.number_hidden_node[i])))\n",
        "      self.weight[\"b\" + str(i+1)] = (np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[i+1], 1)))\n",
        "    self.weight[\"w\" + str(self.number_hidden_layer)] = np.random.normal(loc=0, scale=0.14, size=(self.number_class_output * self.distance_dim, self.number_hidden_node[self.number_hidden_layer-1]))\n",
        "    self.weight[\"b\" + str(self.number_hidden_layer)] = np.random.normal(loc=0, scale=0.14, size=(self.number_class_output * self.distance_dim, 1))\n",
        "    \n",
        "  def forward(self, data):\n",
        "    self.layer.clear()\n",
        "    self.layer[\"input\"] = data\n",
        "    if len(data) == data.size:\n",
        "      self.layer[\"z0\"] = (np.matmul(self.weight[\"w0\"],np.transpose(data))).reshape((len(MyNetwork.weight[\"w0\"]),1))\n",
        "    else:\n",
        "      self.layer[\"z0\"] = (np.matmul(self.weight[\"w0\"], np.transpose(data)))\n",
        "    self.layer[\"z0\"] = np.add(self.layer[\"z0\"], self.weight[\"b0\"])\n",
        "    self.layer[\"r0\"] = gelu(self.layer[\"z0\"])\n",
        "    self.layer[\"s0\"] = Dgelu(self.layer[\"z0\"])\n",
        "    for i in range(self.number_hidden_layer - 1):\n",
        "      self.layer[\"z\" + str(i + 1)] = np.matmul(self.weight[\"w\" + str(i + 1)], self.layer[\"r\" + str(i)])\n",
        "      self.layer[\"z\" + str(i + 1)] = np.add(self.layer[\"z\" + str(i + 1)], self.weight[\"b\" + str(i + 1)])\n",
        "      self.layer[\"r\" + str(i + 1)] = gelu(self.layer[\"z\" + str(i + 1)])\n",
        "      self.layer[\"s\" + str(i + 1)] = Dgelu(self.layer[\"z\" + str(i + 1)])\n",
        "    self.layer[\"z\" + str(self.number_hidden_layer)] = np.matmul(self.weight[\"w\" + str(self.number_hidden_layer)], self.layer[\"r\" + str(self.number_hidden_layer - 1)])\n",
        "    self.layer[\"z\" + str(self.number_hidden_layer)] = np.add(self.layer[\"z\" + str(self.number_hidden_layer)], self.weight[\"b\" + str(self.number_hidden_layer)])\n",
        "    self.layer[\"r\" + str(self.number_hidden_layer)] = RBF_encode(self.layer[\"z\" + str(self.number_hidden_layer)], self.number_class_output, self.distance_dim)\n",
        "    self.layer[\"s\" + str(self.number_hidden_layer)] = np.sign(self.layer[\"z\" + str(self.number_hidden_layer)])\n",
        "    self.score = self.layer[\"r\" + str(self.number_hidden_layer)]\n",
        "    #print(np.transpose(self.score))\n",
        "    temp = self.decide_RBF(self.score, self.landa)\n",
        "    return temp\n",
        "  \n",
        "  def decide_RBF(self, data, landa):\n",
        "    self.result = np.argmin(data, axis=0)\n",
        "    self.result[np.min(data, axis=0)>landa] = 10\n",
        "    return self.result\n",
        "\n",
        "  def cal_loss(self, label):\n",
        "    self.loss.clear()\n",
        "    self.back_prob_output = []\n",
        "    temp = np.transpose(self.score)\n",
        "    for i in range(len(label)):\n",
        "      if label[i] != 10:\n",
        "        self.loss.append(np.sum(relu((self.landa - temp[i]))) - relu(self.landa- temp[i][label[i]]) +   temp[i][int(label[i])])\n",
        "      else:\n",
        "        self.loss.append(np.sum(relu(self.landa - temp[i])))\n",
        "      self.back_prob_output.append(encode(temp[i], label[i], self.landa))\n",
        "    self.back_prob_output = np.transpose(self.back_prob_output)/len(label)\n",
        "    total_loss = np.sum(self.loss)/len(self.loss)\n",
        "    self.loss_graph.append(total_loss)\n",
        "    return total_loss\n",
        "\n",
        "  def batching(self, data, label):\n",
        "    batch_size = self.batchS\n",
        "    if len(data) == data.size:\n",
        "      batch[0] = data\n",
        "      return\n",
        "    for i in range(int(len(data)/batch_size)):\n",
        "      self.batch_data[i] = data[i*batch_size:(i+1)*batch_size]\n",
        "      self.batch_label[i] = label[i*batch_size:(i+1)*batch_size]\n",
        "    if len(data)%batch_size != 0:\n",
        "      self.batch_data[int(len(data)/batch_size)] = data[int(len(data)/batch_size)*batch_size:len(data)]\n",
        "      self.batch_label[int(len(data)/batch_size)] = label[int(len(data)/batch_size)*batch_size:len(data)]\n",
        "\n",
        "  def back_prob(self):\n",
        "    temp = np.multiply(expand(self.back_prob_output), self.layer[\"s\" + str(self.number_hidden_layer)])\n",
        "    for i in range(self.number_hidden_layer):\n",
        "      self.diff_weight[\"w\" + str(self.number_hidden_layer - i)] = np.matmul(temp, np.transpose(self.layer[\"r\"+ str(self.number_hidden_layer-1-i)]))\n",
        "      self.diff_weight[\"b\" + str(self.number_hidden_layer - i)] = np.matmul(temp, np.ones((len(temp[0]), 1)))\n",
        "      temp = np.matmul(np.transpose(self.weight[\"w\" + str(self.number_hidden_layer - i)]), temp)\n",
        "      temp = np.multiply(self.layer[\"s\" + str(self.number_hidden_layer - i - 1)], temp)\n",
        "    self.diff_weight[\"w0\"] = np.matmul(temp, self.layer[\"input\"])\n",
        "    self.diff_weight[\"b0\"] = np.matmul(temp, np.ones((len(temp[0]), 1)))\n",
        "\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.diff_weight[\"w\" + str(i) + \"_prev\"] = ((1 - self.momentum) * self.diff_weight[\"w\" + str(i)] + self.momentum * self.diff_weight[\"w\" + str(i) + \"_prev\"])\n",
        "      self.diff_weight[\"b\" + str(i) + \"_prev\"] = ((1 - self.momentum) * self.diff_weight[\"b\" + str(i)] + self.momentum * self.diff_weight[\"b\" + str(i) + \"_prev\"])\n",
        "\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.weight[\"w\" + str(i)] = self.weight[\"w\" + str(i)] - self.diff_weight[\"w\" + str(i) + \"_prev\"] * self.learning_rate\n",
        "      self.weight[\"b\" + str(i)] = self.weight[\"b\" + str(i)] - self.diff_weight[\"b\" + str(i) + \"_prev\"] * self.learning_rate\n",
        "\n",
        "  def Train_Network(self, data, label):\n",
        "    epoch = 0\n",
        "    for j in range(self.number_turn):\n",
        "      self.batching(data, label)\n",
        "      for i in range(len(self.batch_data)):\n",
        "        self.forward(self.batch_data[i])\n",
        "        self.accuracy_graph.append(Cal_accuracy(self.batch_label[i], self.forward(self.batch_data[i])))\n",
        "        print(self.cal_loss(self.batch_label[i]), \" step \", i,\" of the epoch \", j , \"the steps is: \", epoch)\n",
        "        self.back_prob()\n",
        "        epoch += 1\n",
        "\n",
        "  def Test_Network(self, data, label):\n",
        "    if(len(data) == data.size):\n",
        "      temp = self.batchS\n",
        "      self.batchS = 1\n",
        "      print(Cal_accuracy(label, MyNetwork.forward(data)))\n",
        "      self.batchS = temp\n",
        "    else:\n",
        "      print(Cal_accuracy(label, MyNetwork.forward(data)))\n",
        "\n",
        "  def attack_network(self, data, label):\n",
        "    self.forward(data)\n",
        "    self.cal_loss(label)\n",
        "    D_image = np.multiply(expand(self.back_prob_output), self.layer[\"s\" + str(self.number_hidden_layer)])\n",
        "    for i in range(self.number_hidden_layer):\n",
        "      D_image = np.matmul(np.transpose(self.weight[\"w\" + str(self.number_hidden_layer - i)]), D_image)\n",
        "      D_image = np.multiply(self.layer[\"s\" + str(self.number_hidden_layer - i - 1)], D_image)\n",
        "    D_image = np.matmul(np.transpose(self.weight[\"w0\"]), D_image)\n",
        "    D_image = np.sign(D_image) \n",
        "    return data - self.attack_rate * D_image.reshape((-1,))\n",
        "\n",
        "  def set_landa(self,x):\n",
        "    self.landa = x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDWCuLu0xOt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyNetwork = Network(128,1,[150] ,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU1H5KjrxUBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyNetwork.set_learning_rate(0.05)\n",
        "MyNetwork.set_turn(3)\n",
        "MyNetwork.set_batch_size(128)\n",
        "MyNetwork.Train_Network(Train_data, Train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhiEW5BbxaVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35e760f7-a89f-4f31-e9b6-2cca6c1a9ac8"
      },
      "source": [
        "MyNetwork.Test_Network(Train_data, Train_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.815813953488372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beoVyPHHyIRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mini_dataSet, mini_labelSet = [],[]\n",
        "j = 0\n",
        "for i in range(1000):\n",
        "  if MyNetwork.forward(Train_data[i]) == Train_label[i]:\n",
        "    mini_dataSet.append(Train_data[i])\n",
        "    mini_labelSet.append(Train_label[i])\n",
        "    j += 1\n",
        "  if j == 100:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHjdFtvXxpGO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attacked_image = []\n",
        "for i in range(100):\n",
        "  attacked_image.append(MyNetwork.attack_network(mini_dataSet[i], mini_labelSet[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-3ztNA5xrNf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score1 = 0\n",
        "score2 = 0\n",
        "for i in range(100):\n",
        "  print(\"The label for the\", i,\"th data is: \", MyNetwork.forward(mini_dataSet[i]), \"after attack it became: \", MyNetwork.forward(attacked_image[i].reshape((-1,))))\n",
        "  if MyNetwork.forward(mini_dataSet[i]) != MyNetwork.forward(attacked_image[i].reshape((-1,))):\n",
        "    score1 += 1\n",
        "  if 10 ==  MyNetwork.forward(attacked_image[i].reshape((-1,))):\n",
        "    score2 += 1\n",
        "print(\"The attacked accuracy was: \", score1)\n",
        "print(\"The number rejection is: \", score2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}