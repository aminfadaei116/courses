{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q6_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3YzLRA3QeL0evGh89ij6e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfadaei116/Deep-Learning-Course/blob/master/CA1/Q6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUwYBhHmDhou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f45cab43-f706-4e1a-aec5-cd3169334554"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaNTNyJSzc7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg as LA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwJs1ur0zo-X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/Reduced_Test_Data.csv', header = None)\n",
        "Test_label = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/testLabels.csv', header = None)\n",
        "Train_data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/Reduced_Train_Data.csv', header = None)\n",
        "Train_label = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/trainLabels.csv', header = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqrcNUUhzpoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_data = Test_data.to_numpy()\n",
        "Test_label = Test_label.to_numpy()\n",
        "Train_data = Train_data.to_numpy()\n",
        "Train_label = Train_label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQGMy07d0SVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxD = np.max(Train_data, axis=0)\n",
        "minD = np.min(Train_data, axis=0)\n",
        "delta = maxD - minD\n",
        "Train_data = Train_data - minD\n",
        "Test_data = Test_data - minD\n",
        "Train_data = 2 * (Train_data/delta) - 1\n",
        "Test_data = 2 * (Test_data/delta) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g47ywWzF0UNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "  return np.maximum(x, np.zeros_like(x))\n",
        "\n",
        "def Cal_accuracy(True_label, Estimated_label):\n",
        "  return np.count_nonzero(np.transpose(True_label)==np.array(Estimated_label))/True_label.size\n",
        "\n",
        "def step(x):\n",
        "  return 1*(x > np.zeros_like(x))\n",
        "\n",
        "def encode(vect, idx, landa):\n",
        "  temp = np.multiply(step(landa - vect),-1)\n",
        "  temp[idx] = 1\n",
        "  return temp\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5 * np.multiply(x, 1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "def Dgelu(x):\n",
        "  return np.divide(0.053516 * np.power(x, 3) + np.multiply(0.398942, x) , np.power(np.cosh(0.0356774 * np.power(x, 3) +np.multiply(0.79788, x)),2)) + 0.5 * ( 1 + np.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * np.power(x, 3))))\n",
        "\n",
        "def RBF_encode(data, number_class, dim):\n",
        "  data = np.reshape(data, (dim,int(data.size/dim)), order='F')\n",
        "  data = LA.norm(data,1, axis = 0)\n",
        "  data = np.reshape(data, (number_class, int(data.size/number_class)), order='F')\n",
        "  return data\n",
        "\n",
        "def expand(x):\n",
        "  temp = []\n",
        "  for i in range(len(x)):\n",
        "    temp.append(x[i])\n",
        "    temp.append(x[i])\n",
        "  return temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V_kX7BQ0WEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network:\n",
        "  def __init__(self, input_node, hidden_layer, hidden_node, output_node):\n",
        "    self.number_input_node = input_node\n",
        "    self.number_hidden_layer = hidden_layer\n",
        "    self.number_hidden_node = hidden_node\n",
        "    self.number_class_output = output_node\n",
        "    self.distance_dim = 2\n",
        "    self.weight = {}\n",
        "    self.layer = {}\n",
        "    self.batch_data = {}\n",
        "    self.batch_label = {}\n",
        "    self.diff_weight = {}\n",
        "    self.score = []\n",
        "    self.result = []\n",
        "    self.init_weight()\n",
        "    self.loss = []\n",
        "    self.back_prob_output = []\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.diff_weight[\"w\" + str(i) + \"_prev\"] = 0\n",
        "      self.diff_weight[\"b\" + str(i) + \"_prev\"] = 0\n",
        "    self.momentum = 0.9\n",
        "    self.learning_rate = 0.001\n",
        "    self.number_turn = 100\n",
        "    self.batchS = 128\n",
        "    self.accuracy_graph = []\n",
        "    self.loss_graph = []\n",
        "    self.landa = 550\n",
        "    self.attack_rate = 1\n",
        "\n",
        "  def set_turn(self, x):\n",
        "    self.number_turn = x\n",
        "\n",
        "  def set_learning_rate(self, x):\n",
        "    self.learning_rate = x\n",
        "\n",
        "  def set_batch_size(self, x):\n",
        "    self.batchS = x\n",
        "  \n",
        "  def load_weights(self):\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.weight[\"w\" + str(i)] = (pd.read_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/w\" + str(i) + \".csv\", header=None)).to_numpy()\n",
        "      self.weight[\"b\" + str(i)] = (pd.read_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/b\" + str(i) + \".csv\", header=None)).to_numpy()\n",
        "\n",
        "  def init_weight(self):\n",
        "    self.weight[\"w0\"] = np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[0], self.number_input_node))\n",
        "    self.weight[\"b0\"] = np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[0], 1))\n",
        "    for i in range(self.number_hidden_layer - 1):\n",
        "      self.weight[\"w\" + str(i+1)] = (np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[i+1], self.number_hidden_node[i])))\n",
        "      self.weight[\"b\" + str(i+1)] = (np.random.normal(loc=0, scale=0.14, size=(self.number_hidden_node[i+1], 1)))\n",
        "    self.weight[\"w\" + str(self.number_hidden_layer)] = np.random.normal(loc=0, scale=0.14, size=(self.number_class_output * self.distance_dim, self.number_hidden_node[self.number_hidden_layer-1]))\n",
        "    self.weight[\"b\" + str(self.number_hidden_layer)] = np.random.normal(loc=0, scale=0.14, size=(self.number_class_output * self.distance_dim, 1))\n",
        "    \n",
        "  def forward(self, data):\n",
        "    self.layer.clear()\n",
        "    self.layer[\"input\"] = data\n",
        "    if len(data) == data.size:\n",
        "      self.layer[\"z0\"] = (np.matmul(self.weight[\"w0\"],np.transpose(data))).reshape((len(MyNetwork.weight[\"w0\"]),1))\n",
        "    else:\n",
        "      self.layer[\"z0\"] = (np.matmul(self.weight[\"w0\"], np.transpose(data)))\n",
        "    self.layer[\"z0\"] = np.add(self.layer[\"z0\"], self.weight[\"b0\"])\n",
        "    self.layer[\"r0\"] = gelu(self.layer[\"z0\"])\n",
        "    self.layer[\"s0\"] = Dgelu(self.layer[\"z0\"])\n",
        "    for i in range(self.number_hidden_layer - 1):\n",
        "      self.layer[\"z\" + str(i + 1)] = np.matmul(self.weight[\"w\" + str(i + 1)], self.layer[\"r\" + str(i)])\n",
        "      self.layer[\"z\" + str(i + 1)] = np.add(self.layer[\"z\" + str(i + 1)], self.weight[\"b\" + str(i + 1)])\n",
        "      self.layer[\"r\" + str(i + 1)] = gelu(self.layer[\"z\" + str(i + 1)])\n",
        "      self.layer[\"s\" + str(i + 1)] = Dgelu(self.layer[\"z\" + str(i + 1)])\n",
        "    self.layer[\"z\" + str(self.number_hidden_layer)] = np.matmul(self.weight[\"w\" + str(self.number_hidden_layer)], self.layer[\"r\" + str(self.number_hidden_layer - 1)])\n",
        "    self.layer[\"z\" + str(self.number_hidden_layer)] = np.add(self.layer[\"z\" + str(self.number_hidden_layer)], self.weight[\"b\" + str(self.number_hidden_layer)])\n",
        "    self.layer[\"r\" + str(self.number_hidden_layer)] = RBF_encode(self.layer[\"z\" + str(self.number_hidden_layer)], self.number_class_output, self.distance_dim)\n",
        "    self.layer[\"s\" + str(self.number_hidden_layer)] = np.sign(self.layer[\"z\" + str(self.number_hidden_layer)])\n",
        "    self.score = self.layer[\"r\" + str(self.number_hidden_layer)]\n",
        "    temp = self.decide_RBF(self.score)\n",
        "    return temp\n",
        "  \n",
        "  def decide_RBF(self, data):\n",
        "    self.result = np.argmin(data, axis=0)\n",
        "    return self.result\n",
        "\n",
        "  def cal_loss(self, label):\n",
        "    self.loss.clear()\n",
        "    self.back_prob_output = []\n",
        "    temp = np.transpose(self.score)\n",
        "    for i in range(len(label)):\n",
        "      self.loss.append(np.sum(relu((self.landa - temp[i]))) - relu(self.landa- temp[i][label[i]]) + temp[i][label[i]])\n",
        "      self.back_prob_output.append(encode(temp[i], label[i], self.landa))\n",
        "    self.back_prob_output = np.transpose(self.back_prob_output)/len(label)\n",
        "    total_loss = np.sum(self.loss)/len(self.loss)\n",
        "    self.loss_graph.append(total_loss)\n",
        "    return total_loss\n",
        "\n",
        "  def batching(self, data, label):\n",
        "    batch_size = self.batchS\n",
        "    if len(data) == data.size:\n",
        "      batch[0] = data\n",
        "      return\n",
        "    for i in range(int(len(data)/batch_size)):\n",
        "      self.batch_data[i] = data[i*batch_size:(i+1)*batch_size]\n",
        "      self.batch_label[i] = label[i*batch_size:(i+1)*batch_size]\n",
        "    if len(data)%batch_size != 0:\n",
        "      self.batch_data[int(len(data)/batch_size)] = data[int(len(data)/batch_size)*batch_size:len(data)]\n",
        "      self.batch_label[int(len(data)/batch_size)] = label[int(len(data)/batch_size)*batch_size:len(data)]\n",
        "\n",
        "  def back_prob(self):\n",
        "    temp = np.multiply(expand(self.back_prob_output), self.layer[\"s\" + str(self.number_hidden_layer)])\n",
        "    for i in range(self.number_hidden_layer):\n",
        "      self.diff_weight[\"w\" + str(self.number_hidden_layer - i)] = np.matmul(temp, np.transpose(self.layer[\"r\"+ str(self.number_hidden_layer-1-i)]))\n",
        "      self.diff_weight[\"b\" + str(self.number_hidden_layer - i)] = np.matmul(temp, np.ones((len(temp[0]), 1)))\n",
        "      temp = np.matmul(np.transpose(self.weight[\"w\" + str(self.number_hidden_layer - i)]), temp)\n",
        "      temp = np.multiply(self.layer[\"s\" + str(self.number_hidden_layer - i - 1)], temp)\n",
        "    self.diff_weight[\"w0\"] = np.matmul(temp, self.layer[\"input\"])\n",
        "    self.diff_weight[\"b0\"] = np.matmul(temp, np.ones((len(temp[0]), 1)))\n",
        "\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.diff_weight[\"w\" + str(i) + \"_prev\"] = ((1 - self.momentum) * self.diff_weight[\"w\" + str(i)] + self.momentum * self.diff_weight[\"w\" + str(i) + \"_prev\"])\n",
        "      self.diff_weight[\"b\" + str(i) + \"_prev\"] = ((1 - self.momentum) * self.diff_weight[\"b\" + str(i)] + self.momentum * self.diff_weight[\"b\" + str(i) + \"_prev\"])\n",
        "\n",
        "    for i in range(self.number_hidden_layer + 1):\n",
        "      self.weight[\"w\" + str(i)] = self.weight[\"w\" + str(i)] - self.diff_weight[\"w\" + str(i) + \"_prev\"] * self.learning_rate\n",
        "      self.weight[\"b\" + str(i)] = self.weight[\"b\" + str(i)] - self.diff_weight[\"b\" + str(i) + \"_prev\"] * self.learning_rate\n",
        "\n",
        "  def Train_Network(self, data, label):\n",
        "    epoch = 0\n",
        "    for j in range(self.number_turn):\n",
        "      self.batching(data, label)\n",
        "      for i in range(len(self.batch_data)):\n",
        "        self.forward(self.batch_data[i])\n",
        "        self.accuracy_graph.append(Cal_accuracy(self.batch_label[i], self.forward(self.batch_data[i])))\n",
        "        print(self.cal_loss(self.batch_label[i]), \" step \", i,\" of the epoch \", j , \"the steps is: \", epoch)\n",
        "        self.back_prob()\n",
        "        epoch += 1\n",
        "\n",
        "  def Test_Network(self, data, label):\n",
        "    if(len(data) == data.size):\n",
        "      temp = self.batchS\n",
        "      self.batchS = 1\n",
        "      print(Cal_accuracy(label, MyNetwork.forward(data)))\n",
        "      self.batchS = temp\n",
        "    else:\n",
        "      print(Cal_accuracy(label, MyNetwork.forward(data)))\n",
        "\n",
        "  def attack_network(self, data, label):\n",
        "    self.forward(data)\n",
        "    self.cal_loss(label)\n",
        "    D_image = np.multiply(expand(self.back_prob_output), self.layer[\"s\" + str(self.number_hidden_layer)])\n",
        "    for i in range(self.number_hidden_layer):\n",
        "      D_image = np.matmul(np.transpose(self.weight[\"w\" + str(self.number_hidden_layer - i)]), D_image)\n",
        "      D_image = np.multiply(self.layer[\"s\" + str(self.number_hidden_layer - i - 1)], D_image)\n",
        "    D_image = np.matmul(np.transpose(self.weight[\"w0\"]), D_image)\n",
        "    D_image = np.sign(D_image) \n",
        "    return data - self.attack_rate * D_image.reshape((-1,))\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUrUShDc0gZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyNetwork = Network(128,1,[150] ,10)\n",
        "#MyNetwork.load_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfuryDQp0mqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyNetwork.set_learning_rate(0.05)\n",
        "MyNetwork.set_turn(3)\n",
        "MyNetwork.set_batch_size(128)\n",
        "MyNetwork.Train_Network(Train_data, Train_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grySXwUx1DGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "85de25b7-daf2-4c27-d60a-8f6b7e476639"
      },
      "source": [
        "MyNetwork.Test_Network(Test_data, Test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in power\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_zgRMQfWgd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mini_dataSet, mini_labelSet = [],[]\n",
        "j = 0\n",
        "for i in range(100):\n",
        "  if MyNetwork.forward(Train_data[i]) == Train_label[i]:\n",
        "    mini_dataSet.append(Train_data[i])\n",
        "    mini_labelSet.append(Train_label[i])\n",
        "    j += 1\n",
        "  if j == 10:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkvHTI5m1FL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attacked_image = []\n",
        "for i in range(10):\n",
        "  attacked_image.append(MyNetwork.attack_network(mini_dataSet[i], mini_labelSet[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bRWz_z2XNi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1c6ad9f1-c685-47fc-f331-c2d7f15ff901"
      },
      "source": [
        "score = 0\n",
        "for i in range(10):\n",
        "  print(\"The label for the\", i,\"th data is: \", MyNetwork.forward(mini_dataSet[i]), \"after attack it became: \", MyNetwork.forward(attacked_image[i].reshape((-1,))))\n",
        "  if MyNetwork.forward(mini_dataSet[i]) != MyNetwork.forward(attacked_image[i].reshape((-1,))):\n",
        "    score += 1\n",
        "print(\"The attacked accuracy was: \", score * 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The label for the 0 th data is:  [9] after attack it became:  [8]\n",
            "The label for the 1 th data is:  [0] after attack it became:  [9]\n",
            "The label for the 2 th data is:  [2] after attack it became:  [3]\n",
            "The label for the 3 th data is:  [7] after attack it became:  [0]\n",
            "The label for the 4 th data is:  [2] after attack it became:  [2]\n",
            "The label for the 5 th data is:  [5] after attack it became:  [7]\n",
            "The label for the 6 th data is:  [5] after attack it became:  [7]\n",
            "The label for the 7 th data is:  [0] after attack it became:  [8]\n",
            "The label for the 8 th data is:  [9] after attack it became:  [1]\n",
            "The label for the 9 th data is:  [5] after attack it became:  [8]\n",
            "The attacked accuracy was:  90\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in cosh\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in power\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8jlNv6o0qa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(MyNetwork.number_hidden_layer + 1):\n",
        "  pd.DataFrame(MyNetwork.weight[\"w\" + str(i)]).to_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/w\" + str(i) + \".csv\", index=False, header=False)\n",
        "  pd.DataFrame(MyNetwork.weight[\"b\" + str(i)]).to_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/b\" + str(i) + \".csv\", index=False, header=False)\n",
        "  pd.DataFrame(MyNetwork.accuracy_graph).to_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/accuracy.csv\", index=False, header=False)\n",
        "  pd.DataFrame(MyNetwork.loss_graph).to_csv(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/Fashion-MNIST/loss.csv\", index=False, header=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}