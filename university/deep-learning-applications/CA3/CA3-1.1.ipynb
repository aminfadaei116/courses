{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMyYaOFccOB1B2rElBDtG8J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfadaei116/Deep-Learning-Course/blob/master/CA3/Q1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFQGAHzcOETO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uImuShApewyH",
        "colab_type": "text"
      },
      "source": [
        "Import the Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "739ncglUUdzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import linalg as LA\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "# makes it easy to write user-friendly command-line interfaces\n",
        "import argparse\n",
        "# contains data structures for multi-dimensional tensors\n",
        "# and mathematical operations over theme\n",
        "import torch\n",
        "# helps us in creating and training of the neural network.\n",
        "import torch.nn as nn\n",
        "# contains all the functions in the torch.nn library\n",
        "import torch.nn.functional as F\n",
        "# implements various optimization algorithms\n",
        "import torch.optim as optim\n",
        "# contains datasets with almost similar API\n",
        "from torchvision import datasets\n",
        "# contains common image transformations\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# provides several methods to adjust the learning rate based on the number of epochs\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7Om60ELfxmc",
        "colab_type": "text"
      },
      "source": [
        "Load Data\n",
        "Load Dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxLRmnVdfxEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_Data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW3-DataSet/Q1/Data/TestD.csv', header = None, encoding = \"ISO-8859-1\")\n",
        "Train_Data = pd.read_csv('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW3-DataSet/Q1/Data/TrainD.csv', header = None, encoding = \"ISO-8859-1\")[0:5000]\n",
        "Train_Data.columns = ['label', 'sentence']\n",
        "Test_Data.columns = ['label', 'sentence']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_KQ7WzhmZb",
        "colab_type": "text"
      },
      "source": [
        "Here is the Max size of sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HwskDrbhlx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6791d454-9ec1-4b1d-8233-c9dbec0f7687"
      },
      "source": [
        "sentence_size = []\n",
        "for i in range(Train_Data.shape[0]):\n",
        "  sentence_size.append(len(Train_Data.loc[i]['sentence'].split()))\n",
        "max_size = max(sentence_size)\n",
        "print(max_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBdh4uOgf1J7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW3-DataSet/Q1/glove.json', 'r') as my_file:\n",
        "    My_dict = json.load(my_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evw044AaeE0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_float(str_arr):\n",
        "  numbers = str_arr.split()\n",
        "  float_num = [float(num) for num in numbers]\n",
        "  return float_num\n",
        "\n",
        "def zerolistmaker(n):\n",
        "  listofzeros = [0] * n\n",
        "  return listofzeros\n",
        "\n",
        "def calc_acc(output1, batch_y, num):\n",
        "  return ((torch.argmax(output1, dim=1) == batch_y).sum().to(dtype=torch.float32))/num\n",
        "\n",
        "# this part has been taken from the internet and it is from the https://scikit-learn.org/\n",
        "def plot_confusion_matrix(y_true, y_pred, \n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "        \n",
        "\n",
        "\n",
        "def plot_matrix(cm,\n",
        "                title=None,\n",
        "                cmap=plt.cm.Blues):\n",
        "    \n",
        "    if not title:\n",
        "        title = 'Confidence matrix'\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    \n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           title=title,\n",
        "           ylabel='True label',\n",
        "           xlabel='Predicted label')\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    fmt = '.2f'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4yoAU2KuxbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = np.zeros(300)\n",
        "for x in My_dict:\n",
        "  number +=  np.array(string_to_float(My_dict[x]))\n",
        "avg_arr = number / len(My_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al3HFPyZhen9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tweet_Data(Dataset):\n",
        "  def __init__(self, Dict, dataFrame, padding_size):\n",
        "    self.length = dataFrame.shape[0]\n",
        "    self.The_dict = Dict\n",
        "    self.pad_size = padding_size\n",
        "    self.The_df = dataFrame\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    label = torch.tensor(self.The_df.loc[index][\"label\"], dtype = torch.uint8)\n",
        "    tweet = self.The_df.loc[index][\"sentence\"]\n",
        "    words = tweet.split()\n",
        "    temp1 = [(string_to_float(self.The_dict[x]) if x in self.The_dict else avg_arr) for x in words]\n",
        "    temp2 = [zerolistmaker(300) for _ in range(self.pad_size - len(words))]\n",
        "    temp3 = torch.FloatTensor(temp1 + temp2)\n",
        "    return int(label), temp3.view(self.pad_size, 300)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Zt64Ta4tDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_SIZE = 40 #max_size + 1\n",
        "DataSize = len(Train_Data)\n",
        "MyTrainDataSet = Tweet_Data(My_dict, Train_Data[0:int(DataSize*0.95)], PAD_SIZE)\n",
        "MyValidactionDataSet =Tweet_Data(My_dict, Train_Data[int(DataSize*0.95):].reset_index(), PAD_SIZE)\n",
        "MyTestDataSet = Tweet_Data(My_dict,Test_Data, PAD_SIZE)\n",
        "BATCH_SIZE = 16\n",
        "TrainData = torch.utils.data.DataLoader(dataset=MyTrainDataSet, batch_size=BATCH_SIZE, shuffle=True)\n",
        "ValidationData = torch.utils.data.DataLoader(dataset=MyValidactionDataSet)\n",
        "TestData = torch.utils.data.DataLoader(dataset=MyTestDataSet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXrGHrHGoCrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_NET(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LSTM_NET, self).__init__()\n",
        "    self.lstm_layer = nn.LSTM(input_size = 300,  hidden_size = 150, num_layers = 1, batch_first = True)\n",
        "    self.Fc1 = nn.Linear(150,3)\n",
        "    self.SM1 = nn.Softmax()\n",
        "    self.train_loss = []\n",
        "    self.test_loss = []\n",
        "    self.val_loss = []\n",
        "    self.acc_train = []\n",
        "    self.acc_test = []\n",
        "    self.acc_val = []\n",
        "\n",
        "  def forward(self, input2):\n",
        "\n",
        "    h0 = torch.randn(1, input2.size(0), 150)\n",
        "    c0 = torch.randn(1, input2.size(0), 150)\n",
        "    out, (hn,cn) = self.lstm_layer(input2)\n",
        "    out = self.Fc1(out[:,-1,:])\n",
        "    out = F.softmax(out, dim=1)\n",
        "    return  out\n",
        "\n",
        "\n",
        "def Train_NetWork(model, learning_rate, epoch_number, wr):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  model.train()\n",
        "  for epoch in range(epoch_number):\n",
        "    for i, (labels, inputs) in enumerate(TrainData):\n",
        "      optimizer.zero_grad()\n",
        "      output2 = model.forward(inputs)\n",
        "      loss = F.cross_entropy(output2, labels)\n",
        "      model.acc_train.append(calc_acc(output2, labels, BATCH_SIZE))\n",
        "      model.train_loss.append(loss)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      print(\"epoch: \", epoch, \" loss for batch: \", loss)\n",
        "      if i % 200 == 0:\n",
        "        Test_acc(model)\n",
        "\n",
        "def Test_Val(model):\n",
        "  loss = 0\n",
        "  pred = []\n",
        "  real = []\n",
        "  N = len(MyValidactionDataSet)\n",
        "  print(\"testing\")\n",
        "  for i in range(N):\n",
        "    score = MyNetWork.forward(MyValidactionDataSet[i][1].view(-1,40,300))\n",
        "    label = torch.tensor(MyValidactionDataSet[i][0]).view(-1)\n",
        "    pred.append(torch.argmax(score).item())\n",
        "    real.append(label)\n",
        "    loss += F.cross_entropy(score, label)\n",
        "  model.val_loss.append(loss)\n",
        "  print(loss/N)\n",
        "  plot_confusion_matrix(real, pred)\n",
        "\n",
        "  loss = 0\n",
        "  pred = []\n",
        "  real = []\n",
        "  N = len(MyTestDataSet)\n",
        "  for i in range(N):\n",
        "    score = MyNetWork.forward(MyTestDataSet[i][1].view(-1,40,300))\n",
        "    label = torch.tensor(MyTestDataSet[i][0]).view(-1)\n",
        "    pred.append(torch.argmax(score).item())\n",
        "    real.append(label)\n",
        "    loss += F.cross_entropy(score, label)\n",
        "  model.val_loss.append(loss)\n",
        "  print(loss/N)\n",
        "  plot_confusion_matrix(real, pred)\n",
        " \n",
        "\n",
        "def Test_acc(model):\n",
        "  N = len(MyTestDataSet)\n",
        "  loss = 0\n",
        "  pred = []\n",
        "  real = []\n",
        "  for i in range(N):\n",
        "    score = model.forward(MyTestDataSet[i][1].view(-1,40,300))\n",
        "    label = torch.tensor(MyTestDataSet[i][0]).view(-1)\n",
        "    pred.append(torch.argmax(score).item())\n",
        "    real.append(label)\n",
        "    loss += F.cross_entropy(score, label)\n",
        "  model.acc_test.append(accuracy_score(real, pred))\n",
        "  model.test_loss.append(loss/N)\n",
        "  print(\"The Test loss: \", model.test_loss[-1], \"The Test accuracy: \", model.acc_test[-1])\n",
        "  loss = 0\n",
        "  pred = []\n",
        "  real = []\n",
        "  N = len(MyValidactionDataSet)\n",
        "  for i in range(N):\n",
        "    score = model.forward(MyValidactionDataSet[i][1].view(-1,40,300))\n",
        "    label = torch.tensor(MyValidactionDataSet[i][0]).view(-1)\n",
        "    pred.append(torch.argmax(score).item())\n",
        "    real.append(label)\n",
        "    loss += F.cross_entropy(score, label)\n",
        "  model.acc_val.append(accuracy_score(real, pred))\n",
        "  model.val_loss.append(loss/N)\n",
        "\n",
        "  \n",
        "def plot_acc(model):\n",
        "  plt.plot(np.arange(1,len(model.train_loss)+1), model.train_loss)\n",
        "  plt.ylabel('loss of Train')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.plot(np.arange(1,len(model.acc_train)+1), model.acc_train)\n",
        "  plt.ylabel('accuracy of Train')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.plot(np.arange(1,len(model.val_loss)+1), model.val_loss)\n",
        "  plt.ylabel('loss of Val')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.plot(np.arange(1,len(model.acc_val)+1), model.acc_val)\n",
        "  plt.ylabel('accuracy of Val')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.plot(np.arange(1,len(model.test_loss)+1), model.test_loss)\n",
        "  plt.ylabel('loss of Test')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.plot(np.arange(1,len(model.acc_test)+1), model.acc_test)\n",
        "  plt.ylabel('accuracy of Test')\n",
        "  plt.xlabel(\"number steps\")\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNH9e01HZl4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MyNetWork = LSTM_NET()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZwKd7fHoWfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_NetWork(MyNetWork, learning_rate=0.001, epoch_number=30,wr= 0.005)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FdmlGoh4p-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_acc(MyNetWork)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3EM1sI2TEj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_Val(MyNetWork)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFYhRPqUknzs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Test_Val(MyNetWork)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}