{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q2-PreData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+GIQWzTh5X0/FTyLSLjik",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminfadaei116/Deep-Learning-Course/blob/master/CA2/Q2_PreData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HLQVjLc_E2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S5Z6_yA6ctp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from scipy.io import loadmat\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyraBJSh_LWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "print('Beginning file download with urllib2...')\n",
        "\n",
        "url = 'ftp://guest:GU.205dldo@ftp.softronics.ch/mvtec_anomaly_detection/hazelnut.tar.xz'\n",
        "urllib.request.urlretrieve(url, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut.tar.xz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZwvb0x_C5Gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "my_tar = tarfile.open('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut.tar.xz')\n",
        "my_tar.extractall('/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiBLyUuREC2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 128, 128\n",
        "dim = (width, height)\n",
        "\n",
        "img_tensor = torch.zeros((391, 128, 128, 3))\n",
        "\n",
        "for i in range(391):\n",
        "    number = \"{0:0=3d}\".format(i)\n",
        "    img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/train/good/\" + number + \".png\")\n",
        "    img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img_tensor[i] = torch.FloatTensor(img_resized)\n",
        "    print(i/391)\n",
        "  \n",
        "\n",
        "torch.save(img_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_good_tensor.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_bqy1HtPrnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 256, 256\n",
        "dim = (width, height)\n",
        "\n",
        "img_tensor = torch.zeros((391, width, height, 3))\n",
        "\n",
        " \n",
        "\n",
        "for i in range(391):\n",
        "    number = \"{0:0=3d}\".format(i)\n",
        "    img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/train/good/\" + number + \".png\")\n",
        "    img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img_tensor[i] = torch.FloatTensor(img_resized)\n",
        "    print(i/391)\n",
        "  \n",
        "\n",
        "torch.save(img_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_original_good_tensor.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRvnrgHBNzPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 128, 128\n",
        "dim = (width, height)\n",
        "\n",
        "name = [\"crack\", \"cut\", \"hole\", \"print\"]\n",
        "num_img = [18, 17, 18, 17]\n",
        "\n",
        "\n",
        " \n",
        "for j in range(4):\n",
        "  temp_tensor = torch.zeros((num_img[j], 128, 128, 3))\n",
        "  for i in range(num_img[j]):\n",
        "      number = \"{0:0=3d}\".format(i)\n",
        "      img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/test/\" + name[j] + \"/\" + number + \".png\")\n",
        "      img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      temp_tensor[i] = torch.FloatTensor(img_resized)\n",
        "      print(i/num_img[j])\n",
        "  torch.save(temp_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_' + name[j] + '_tensor.pt')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhTTk1i290ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 128, 128\n",
        "dim = (width, height)\n",
        "\n",
        "name = [\"crack\", \"cut\", \"hole\", \"print\"]\n",
        "num_img = [18, 17, 18, 17]\n",
        "\n",
        "\n",
        " \n",
        "for j in range(4):\n",
        "  temp_tensor = torch.zeros((num_img[j], 128, 128))\n",
        "  for i in range(num_img[j]):\n",
        "      number = \"{0:0=3d}\".format(i)\n",
        "      img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/ground_truth/\" + name[j] + \"/\" + number + \"_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
        "      img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      temp_tensor[i] = torch.FloatTensor(img_resized)\n",
        "      print(i/num_img[j])\n",
        "  torch.save(temp_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/small_hazelnut_' + name[j] + '_mask.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ_8NVTz3w4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 256, 256\n",
        "dim = (width, height)\n",
        "\n",
        "name = [\"crack\", \"cut\", \"hole\", \"print\"]\n",
        "num_img = [18, 17, 18, 17]\n",
        "\n",
        "\n",
        " \n",
        "for j in range(4):\n",
        "  temp_tensor = torch.zeros((num_img[j], 256, 256))\n",
        "  for i in range(num_img[j]):\n",
        "      number = \"{0:0=3d}\".format(i)\n",
        "      img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/ground_truth/\" + name[j] + \"/\" + number + \"_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
        "      img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      temp_tensor[i] = torch.FloatTensor(img_resized)\n",
        "      print(i/num_img[j])\n",
        "  torch.save(temp_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_' + name[j] + '_mask.pt')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXpLaxv7OoHW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width, height = 256, 256\n",
        "dim = (width, height)\n",
        "\n",
        "name = [\"crack\", \"cut\", \"hole\", \"print\"]\n",
        "num_img = [18, 17, 18, 17]\n",
        "\n",
        "\n",
        " \n",
        "for j in range(4):\n",
        "  temp_tensor = torch.zeros((num_img[j], width, height, 3))\n",
        "  for i in range(num_img[j]):\n",
        "      number = \"{0:0=3d}\".format(i)\n",
        "      img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/test/\" + name[j] + \"/\" + number + \".png\")\n",
        "      img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "      temp_tensor[i] = torch.FloatTensor(img_resized)\n",
        "      print(i/num_img[j])\n",
        "  torch.save(temp_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_original_' + name[j] + '_tensor.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3aqZwAXlh_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "angle90 = 90\n",
        "angle180 = 180\n",
        "angle270 = 270\n",
        "\n",
        "angle = [90, 180, 270]\n",
        "\n",
        "width, height = 256, 256\n",
        "dim = (width, height)\n",
        "center = (width / 2, height / 2)\n",
        "scale = 1\n",
        "\n",
        "img_tensor = torch.zeros((391*4, width, height, 3))\n",
        "\n",
        " \n",
        "\n",
        "for i in range(391):\n",
        "    number = \"{0:0=3d}\".format(i)\n",
        "    img = cv2.imread(\"/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut/train/good/\" + number + \".png\")\n",
        "    img_resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
        "    img_tensor[i*4] = torch.FloatTensor(img_resized)\n",
        "    for j in range(3):\n",
        "      M = cv2.getRotationMatrix2D(center, angle[j], scale)\n",
        "      rotated_img = cv2.warpAffine(img_resized, M, (height, width))\n",
        "      img_tensor[i*4+j] = torch.FloatTensor(rotated_img)\n",
        "\n",
        "    print(i/391)\n",
        "  \n",
        "\n",
        "torch.save(img_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_original_augmentation_good_tensor.pt')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kJgLEw_qnzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(img_tensor, '/content/drive/My Drive/Deep Learning Course Spring 99/DataSets/HW2-DataSet/Q2-DataSet/hazelnut/hazelnut_original_augmentation_good_tensor.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}